{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stemming.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO9r9AEPdE4KFDJIOAskRRb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Stemming"
      ],
      "metadata": {
        "id": "rgUKGM5vT1kz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For instance, searching for \"boat\" might also return \"boats\" and \"boating\". Here, \"boat\" would be the stem for [boat, boater, boating, boats]."
      ],
      "metadata": {
        "id": "0IKkOtYUT_CF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Stemming is a somewhat crude method for cataloging related words; it essentially chops off letters from the end until the stem is reached. \n",
        "- This works fairly well in most cases, but unfortunately English has many exceptions where a more sophisticated process is required.\n",
        "- In fact, spaCy doesn't include a stemmer, opting instead to rely entirely on lemmatization. \n",
        "\n",
        "Instead, we'll use another popular NLP tool called nltk, which stands for Natural Language Toolkit. For more information on nltk visit https://www.nltk.org/"
      ],
      "metadata": {
        "id": "QEYAOXAYUBQ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Porter Stemmer"
      ],
      "metadata": {
        "id": "u-EP6-iwUWHC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "P3ozlil9Twnv"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "\n",
        "from nltk.stem.porter import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p_stemmer = PorterStemmer()"
      ],
      "metadata": {
        "id": "gowYiMo5Uomt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['run','runner','running','ran','runs','easily','fairly','fairness']"
      ],
      "metadata": {
        "id": "UuilEDOrUqZs"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word + ' --> ' + p_stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfxRtBplUtHV",
        "outputId": "cd21cb88-169b-43df-ede0-64d086e0c7d3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run --> run\n",
            "runner --> runner\n",
            "running --> run\n",
            "ran --> ran\n",
            "runs --> run\n",
            "easily --> easili\n",
            "fairly --> fairli\n",
            "fairness --> fair\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Snowball Stemmer"
      ],
      "metadata": {
        "id": "AKSHXN4sVONE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The algorithm used here is more acurately called the `\"English Stemmer\"` or `\"Porter2 Stemmer\"`. It offers a slight improvement over the original Porter stemmer, both in logic and speed. Since nltk uses the name SnowballStemmer, we'll use it here."
      ],
      "metadata": {
        "id": "KRSzyCeQVU0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "# The Snowball Stemmer requires that you pass a language parameter\n",
        "s_stemmer = SnowballStemmer(language='english')"
      ],
      "metadata": {
        "id": "axYCJmBZVHUl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['run','runner','running','ran','runs','easily','fairly']"
      ],
      "metadata": {
        "id": "mp_EHTzrVeUH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word+' --> '+s_stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkL4e62AVf7F",
        "outputId": "8d3b81d2-8912-4602-ce94-738057c37e23"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run --> run\n",
            "runner --> runner\n",
            "running --> run\n",
            "ran --> ran\n",
            "runs --> run\n",
            "easily --> easili\n",
            "fairly --> fair\n",
            "fairness --> fair\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Try it by yourself!"
      ],
      "metadata": {
        "id": "0N_c0LPMVkiL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['consolingly']"
      ],
      "metadata": {
        "id": "Zqpf1dw6VmS-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Porter Stemmer:')\n",
        "for word in words:\n",
        "  print(word+' --> '+p_stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUgX8PCcVose",
        "outputId": "23841cf6-fe40-4938-f726-5711bb8c4953"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Porter Stemmer:\n",
            "consolingly --> consolingli\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Porter2 Stemmer:')\n",
        "for word in words:\n",
        "  print(word+' --> '+s_stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_CR6hfOVou8",
        "outputId": "44e66238-6e09-44a0-c97d-92fc421174fa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Porter2 Stemmer:\n",
            "consolingly --> consol\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stemming has its drawbacks. If given the token `saw`, stemming might always return `saw`, whereas lemmatization would likely return either `see` or `saw` depending on whether the use of the token was as a verb or a noun."
      ],
      "metadata": {
        "id": "K4SlmWQRWB0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "phrase = 'I am meeting him tomorrow at the meeting'\n",
        "for word in phrase.split():\n",
        "  print(word+' --> '+p_stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJ7cjIyvVoye",
        "outputId": "f93de905-c001-403a-c91f-6116fb1095fe"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I --> i\n",
            "am --> am\n",
            "meeting --> meet\n",
            "him --> him\n",
            "tomorrow --> tomorrow\n",
            "at --> at\n",
            "the --> the\n",
            "meeting --> meet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here the word \"meeting\" appears twice - once as a verb, and once as a noun, and yet the stemmer treats both equally."
      ],
      "metadata": {
        "id": "HTNOjzHMWUGR"
      }
    }
  ]
}